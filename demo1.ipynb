{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import Value\n",
    "\n",
    "a = Value(2.0, label='a')\n",
    "b = Value(-3.0, label='b')\n",
    "c = Value(10.0, label='c')\n",
    "e = a*b; e.label = 'e'\n",
    "d = e + c; d.label = 'd'\n",
    "f = Value(-2.0, label='f')\n",
    "L = d * f; L.label = 'L'\n",
    "L.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'e', 'c', 'd', 'f', 'L']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L.function\n",
    "L.topo_sort()\n",
    "# a = Value(2.0, label='a')\n",
    "# b = a+a\n",
    "# b.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071066904050358\n",
      "--\n",
      "x2 0.5000001283844369\n",
      "w2 0.0\n",
      "x1 -1.5000003851533106\n",
      "w1 1.0000002567688737\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define inputs and set requires_grad=True for gradient calculation\n",
    "x1 = torch.Tensor([2.0]).double(); x1.requires_grad = True\n",
    "x2 = torch.Tensor([0.0]).double(); x2.requires_grad = True\n",
    "\n",
    "# Define weights and bias as scalar tensors with requires_grad=True\n",
    "w1 = torch.Tensor([-3.0]).double(); w1.requires_grad = True\n",
    "w2 = torch.Tensor([1.0]).double(); w2.requires_grad = True\n",
    "b = torch.Tensor([6.8813735870195432]); b.double().requires_grad = True\n",
    "\n",
    "# Define the computation\n",
    "n = x1 * w1 + x2 * w2 + b\n",
    "o = torch.tanh(n)\n",
    "\n",
    "# Print the output value\n",
    "print(o.item())\n",
    "\n",
    "# Perform backpropagation\n",
    "o.backward()\n",
    "\n",
    "# Print the gradients\n",
    "print('--')\n",
    "print('x2', x2.grad.item())\n",
    "print('w2', w2.grad.item())\n",
    "print('x1', x1.grad.item())\n",
    "print('w1', w1.grad.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import MLP\n",
    "\n",
    "n = MLP(3, [4,4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, -1.0, -1.0] \n",
    "]\n",
    "\n",
    "ys = [1.0, -1.0, -1.0, 1.0]\n",
    "\n",
    "# ypred = [n(x) for x in xs]\n",
    "# ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value( = 5.706920694979704)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = sum([(yout - ygt)*(yout - ygt) for ygt, yout in zip(ys, ypred)])\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.14705753294475932"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.layers[0].neurons[0].w[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.22058629941713898"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.layers[0].neurons[0].w[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in n.parameters():\n",
    "    p.data += -0.05 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.00010420522958893954\n",
      "1 0.00010382811755649544\n",
      "2 0.00010345360972067549\n",
      "3 0.00010308167963060937\n",
      "4 0.00010271230118950403\n",
      "5 0.00010234544864876392\n",
      "6 0.00010198109660225179\n",
      "7 0.00010161921998060933\n",
      "8 0.00010125979404575371\n",
      "9 0.00010090279438543478\n",
      "10 0.00010054819690791001\n",
      "11 0.00010019597783673666\n",
      "12 9.984611370565976e-05\n",
      "13 9.949858135357269e-05\n",
      "14 9.915335791962177e-05\n",
      "15 9.88104208383696e-05\n",
      "16 9.846974783506457e-05\n",
      "17 9.813131692099208e-05\n",
      "18 9.779510638891909e-05\n",
      "19 9.746109480864364e-05\n",
      "20 9.712926102259563e-05\n",
      "21 9.679958414152921e-05\n",
      "22 9.647204354032394e-05\n",
      "23 9.614661885383425e-05\n",
      "24 9.582328997281576e-05\n",
      "25 9.550203703995693e-05\n",
      "26 9.518284044594989e-05\n",
      "27 9.48656808256604e-05\n",
      "28 9.455053905435238e-05\n",
      "29 9.423739624398264e-05\n",
      "30 9.392623373957809e-05\n",
      "31 9.361703311566826e-05\n",
      "32 9.330977617277451e-05\n",
      "33 9.300444493397982e-05\n",
      "34 9.270102164155647e-05\n",
      "35 9.239948875365295e-05\n",
      "36 9.209982894102154e-05\n",
      "37 9.180202508384535e-05\n",
      "38 9.150606026859135e-05\n",
      "39 9.121191778492436e-05\n",
      "40 9.091958112268497e-05\n",
      "41 9.062903396891185e-05\n",
      "42 9.03402602049177e-05\n",
      "43 9.005324390343353e-05\n",
      "44 8.97679693257762e-05\n",
      "45 8.948442091908138e-05\n",
      "46 8.920258331358982e-05\n",
      "47 8.892244131996415e-05\n",
      "48 8.864397992666868e-05\n",
      "49 8.836718429739202e-05\n",
      "50 8.809203976849791e-05\n",
      "51 8.78185318465396e-05\n",
      "52 8.754664620581562e-05\n",
      "53 8.72763686859561e-05\n",
      "54 8.700768528955357e-05\n",
      "55 8.67405821798363e-05\n",
      "56 8.64750456783984e-05\n",
      "57 8.621106226293066e-05\n",
      "58 8.594861856501968e-05\n",
      "59 8.568770136797457e-05\n",
      "60 8.542829760469697e-05\n",
      "61 8.517039435557329e-05\n",
      "62 8.491397884642028e-05\n",
      "63 8.46590384464276e-05\n",
      "64 8.440556066620581e-05\n",
      "65 8.415353315578176e-05\n",
      "66 8.390294370269213e-05\n",
      "67 8.365378023007762e-05\n",
      "68 8.340603079480787e-05\n",
      "69 8.315968358566043e-05\n",
      "70 8.291472692149981e-05\n",
      "71 8.267114924950209e-05\n",
      "72 8.24289391434184e-05\n",
      "73 8.218808530184238e-05\n",
      "74 8.194857654651914e-05\n",
      "75 8.171040182068343e-05\n",
      "76 8.147355018743088e-05\n",
      "77 8.123801082808674e-05\n",
      "78 8.100377304063675e-05\n",
      "79 8.077082623816183e-05\n",
      "80 8.053915994729623e-05\n",
      "81 8.030876380673142e-05\n",
      "82 8.007962756571146e-05\n",
      "83 7.985174108257881e-05\n",
      "84 7.962509432334178e-05\n",
      "85 7.939967736023576e-05\n",
      "86 7.917548037035185e-05\n",
      "87 7.895249363424635e-05\n",
      "88 7.873070753459608e-05\n",
      "89 7.85101125548581e-05\n",
      "90 7.829069927798026e-05\n",
      "91 7.807245838508855e-05\n",
      "92 7.785538065423114e-05\n",
      "93 7.763945695911969e-05\n",
      "94 7.742467826789959e-05\n",
      "95 7.721103564194728e-05\n",
      "96 7.699852023466226e-05\n",
      "97 7.678712329030655e-05\n",
      "98 7.657683614282905e-05\n",
      "99 7.636765021474246e-05\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "    # forward pass\n",
    "    ypred = [n(x) for x in xs]\n",
    "    loss = sum([(yout - ygt) * (yout - ygt) for ygt, yout in zip(ys, ypred)])\n",
    "\n",
    "    # backward pass\n",
    "    for p in n.parameters():\n",
    "        p.grad = 0.0\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    # learning_rate = 1.0 - 0.9 * k / 100\n",
    "    for p in n.parameters():\n",
    "        p.data += -0.1 * p.grad\n",
    "\n",
    "    print(k, loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value( = 0.9871360890866648),\n",
       " Value( = -0.9899366959902505),\n",
       " Value( = -0.9844953433910328),\n",
       " Value( = 0.985546702889286)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
